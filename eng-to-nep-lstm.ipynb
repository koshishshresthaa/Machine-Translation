{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8503435,"sourceType":"datasetVersion","datasetId":5075111}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing necessary modules\nimport pandas as pd\nimport numpy as np\nimport torch.nn as nn\nimport torch\nimport nltk\nfrom collections import Counter\nfrom torch import optim\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset, DataLoader\nimport random\nfrom nltk.translate.bleu_score import sentence_bleu, corpus_bleu,SmoothingFunction\nimport re\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-05-24T12:06:05.158539Z","iopub.execute_input":"2024-05-24T12:06:05.158912Z","iopub.status.idle":"2024-05-24T12:06:05.164831Z","shell.execute_reply.started":"2024-05-24T12:06:05.158881Z","shell.execute_reply":"2024-05-24T12:06:05.163712Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model_checkpoint=\"/kaggle/working/language_translation_seq2seq.pth\"","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:07.882577Z","iopub.execute_input":"2024-05-24T10:08:07.883034Z","iopub.status.idle":"2024-05-24T10:08:07.887705Z","shell.execute_reply.started":"2024-05-24T10:08:07.883008Z","shell.execute_reply":"2024-05-24T10:08:07.886691Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/npiadsaddas/npi.txt',delimiter='\\t', names=['English','Nepali','Att'])\ndf.drop(columns=['Att'],inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:49.448890Z","iopub.execute_input":"2024-05-24T10:08:49.449864Z","iopub.status.idle":"2024-05-24T10:08:49.506565Z","shell.execute_reply.started":"2024-05-24T10:08:49.449821Z","shell.execute_reply":"2024-05-24T10:08:49.505410Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  English        Nepali\n0    Who?           को?\n1   Hide.  लुकाउनुहोस्।\n2   Hide.          लुक।\n3   Stay.    बस्नुहोस्।\n4  Hello!       नमस्ते!","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Nepali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Who?</td>\n      <td>को?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hide.</td>\n      <td>लुकाउनुहोस्।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hide.</td>\n      <td>लुक।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stay.</td>\n      <td>बस्नुहोस्।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hello!</td>\n      <td>नमस्ते!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Function to add spaces around punctuation\ndef tokenize_sentence(sentence):\n    # Regular expression to add space around punctuation\n    sentence = re.sub(r'([,.!?।])', r' \\1 ', sentence)\n    # Removing extra spaces\n    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n    return sentence\n\ndf['English']=df['English'].apply(tokenize_sentence)\ndf[\"Nepali\"]=df['Nepali'].apply(tokenize_sentence)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:51.375679Z","iopub.execute_input":"2024-05-24T10:08:51.376013Z","iopub.status.idle":"2024-05-24T10:08:51.451274Z","shell.execute_reply.started":"2024-05-24T10:08:51.375988Z","shell.execute_reply":"2024-05-24T10:08:51.450217Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:52.511861Z","iopub.execute_input":"2024-05-24T10:08:52.512489Z","iopub.status.idle":"2024-05-24T10:08:52.518405Z","shell.execute_reply.started":"2024-05-24T10:08:52.512454Z","shell.execute_reply":"2024-05-24T10:08:52.517450Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(2689, 2)"},"metadata":{}}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:52.748864Z","iopub.execute_input":"2024-05-24T10:08:52.749166Z","iopub.status.idle":"2024-05-24T10:08:52.759049Z","shell.execute_reply.started":"2024-05-24T10:08:52.749121Z","shell.execute_reply":"2024-05-24T10:08:52.758053Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   English         Nepali\n0    Who ?           को ?\n1   Hide .  लुकाउनुहोस् ।\n2   Hide .          लुक ।\n3   Stay .    बस्नुहोस् ।\n4  Hello !       नमस्ते !","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Nepali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Who ?</td>\n      <td>को ?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hide .</td>\n      <td>लुकाउनुहोस् ।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hide .</td>\n      <td>लुक ।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stay .</td>\n      <td>बस्नुहोस् ।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hello !</td>\n      <td>नमस्ते !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Creating vocabulary for english","metadata":{}},{"cell_type":"code","source":"#getting all tokens for english\n\n#Add SOS and EOS tokens to the Nepali vocabulary\nenglish_vocab = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2} \n\ntokens_english = [token for x in df['English'] for token in x.split()]\n\n#make the token_counter in order to count the number of times the token appearred in the enitre document\ntoken_counter_english = Counter(tokens_english)\n\n# Create the vocabulary dictionary\nenglish_vocab.update({token: idx + 3 for idx, token in enumerate(token_counter_english)})","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:53.494230Z","iopub.execute_input":"2024-05-24T10:08:53.495363Z","iopub.status.idle":"2024-05-24T10:08:53.507273Z","shell.execute_reply.started":"2024-05-24T10:08:53.495329Z","shell.execute_reply":"2024-05-24T10:08:53.506291Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"len(english_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:53.825699Z","iopub.execute_input":"2024-05-24T10:08:53.826382Z","iopub.status.idle":"2024-05-24T10:08:53.832098Z","shell.execute_reply.started":"2024-05-24T10:08:53.826346Z","shell.execute_reply":"2024-05-24T10:08:53.831182Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"2178"},"metadata":{}}]},{"cell_type":"markdown","source":"Creating vocabulary for Nepali","metadata":{}},{"cell_type":"code","source":"df['Nepali']='<SOS>' + \" \" + df['Nepali'] + \" \" +  '<EOS>'","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:54.406614Z","iopub.execute_input":"2024-05-24T10:08:54.406971Z","iopub.status.idle":"2024-05-24T10:08:54.413855Z","shell.execute_reply.started":"2024-05-24T10:08:54.406943Z","shell.execute_reply":"2024-05-24T10:08:54.412921Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Add SOS and EOS tokens to the Nepali vocabulary\nnepali_vocab = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2} \n\n# Getting all tokens for Nepali and excluding SOS and EOS tokens\ntokens_nepali = [token for x in df['Nepali'] for token in x.split() if token not in ['<SOS>', '<EOS>']]\n\n# Make the token_counter to count the number of times the token appeared in the entire document\ntoken_counter_nepali = Counter(tokens_nepali)\n\n# Update the vocabulary dictionary with other tokens\n# Update the vocabulary dictionary with other tokens\nnepali_vocab.update({token: idx + 3 for idx, token in enumerate(token_counter_nepali)})\n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:54.750510Z","iopub.execute_input":"2024-05-24T10:08:54.751220Z","iopub.status.idle":"2024-05-24T10:08:54.765713Z","shell.execute_reply.started":"2024-05-24T10:08:54.751177Z","shell.execute_reply":"2024-05-24T10:08:54.764522Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"len(nepali_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:55.070997Z","iopub.execute_input":"2024-05-24T10:08:55.071375Z","iopub.status.idle":"2024-05-24T10:08:55.077740Z","shell.execute_reply.started":"2024-05-24T10:08:55.071347Z","shell.execute_reply":"2024-05-24T10:08:55.076751Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"3087"},"metadata":{}}]},{"cell_type":"code","source":"# Convert text to sequences using the vocabulary dictionary\ndf['encoded_english'] = df['English'].apply(lambda x: [english_vocab[token] for token in x.split()])\ndf['encoded_nepali'] = df['Nepali'].apply(lambda x: [nepali_vocab[token] for token in x.split()])\n\n# Convert sequences to tensors and only select the sequence by truncating it to max_length of 20\nmax_length = 20\npadding_index = 2  # Index of <PAD> token\npadded_sequences_english = [seq[:max_length] if len(seq) >= max_length else seq + [padding_index] * (max_length - len(seq)) for seq in df['encoded_english']]\npadded_sequences_nepali = [seq[:max_length] if len(seq) >= max_length else seq + [padding_index] * (max_length - len(seq)) for seq in df['encoded_nepali']]\n\n# Convert the padded sequences to tensors\ndf['padded_sequence_english'] = padded_sequences_english\ndf['padded_sequence_nepali'] = padded_sequences_nepali\n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:55.370065Z","iopub.execute_input":"2024-05-24T10:08:55.370476Z","iopub.status.idle":"2024-05-24T10:08:55.403517Z","shell.execute_reply.started":"2024-05-24T10:08:55.370446Z","shell.execute_reply":"2024-05-24T10:08:55.402520Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:55.688555Z","iopub.execute_input":"2024-05-24T10:08:55.688891Z","iopub.status.idle":"2024-05-24T10:08:55.710711Z","shell.execute_reply.started":"2024-05-24T10:08:55.688865Z","shell.execute_reply":"2024-05-24T10:08:55.709640Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   English                     Nepali encoded_english encoded_nepali  \\\n0    Who ?           <SOS> को ? <EOS>          [3, 4]   [0, 3, 4, 1]   \n1   Hide .  <SOS> लुकाउनुहोस् । <EOS>          [5, 6]   [0, 5, 6, 1]   \n2   Hide .          <SOS> लुक । <EOS>          [5, 6]   [0, 7, 6, 1]   \n3   Stay .    <SOS> बस्नुहोस् । <EOS>          [7, 6]   [0, 8, 6, 1]   \n4  Hello !       <SOS> नमस्ते ! <EOS>          [8, 9]  [0, 9, 10, 1]   \n\n                             padded_sequence_english  \\\n0  [3, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n1  [5, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n2  [5, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n3  [7, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n4  [8, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n\n                              padded_sequence_nepali  \n0  [0, 3, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n1  [0, 5, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n2  [0, 7, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n3  [0, 8, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n4  [0, 9, 10, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Nepali</th>\n      <th>encoded_english</th>\n      <th>encoded_nepali</th>\n      <th>padded_sequence_english</th>\n      <th>padded_sequence_nepali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Who ?</td>\n      <td>&lt;SOS&gt; को ? &lt;EOS&gt;</td>\n      <td>[3, 4]</td>\n      <td>[0, 3, 4, 1]</td>\n      <td>[3, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 3, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hide .</td>\n      <td>&lt;SOS&gt; लुकाउनुहोस् । &lt;EOS&gt;</td>\n      <td>[5, 6]</td>\n      <td>[0, 5, 6, 1]</td>\n      <td>[5, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 5, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hide .</td>\n      <td>&lt;SOS&gt; लुक । &lt;EOS&gt;</td>\n      <td>[5, 6]</td>\n      <td>[0, 7, 6, 1]</td>\n      <td>[5, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 7, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stay .</td>\n      <td>&lt;SOS&gt; बस्नुहोस् । &lt;EOS&gt;</td>\n      <td>[7, 6]</td>\n      <td>[0, 8, 6, 1]</td>\n      <td>[7, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 8, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hello !</td>\n      <td>&lt;SOS&gt; नमस्ते ! &lt;EOS&gt;</td>\n      <td>[8, 9]</td>\n      <td>[0, 9, 10, 1]</td>\n      <td>[8, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 9, 10, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n# Convert 'padded_sequence' to a tensor\npadded_sequences_english = torch.tensor(df['padded_sequence_english'].tolist())\npadded_sequences_nepali = torch.tensor(df['padded_sequence_nepali'].tolist())\n\n# Train-test split\ntrain_sequences_english, test_sequences_english, train_sequences_nepali, test_sequences_nepali = train_test_split(\n    padded_sequences_english, padded_sequences_nepali, test_size=0.2, random_state=42)\n\n# Create TensorDatasets\ntrain_dataset = TensorDataset(train_sequences_english, train_sequences_nepali)\ntest_dataset = TensorDataset(test_sequences_english, test_sequences_nepali)\n\n# Create DataLoaders\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:56.016468Z","iopub.execute_input":"2024-05-24T10:08:56.017081Z","iopub.status.idle":"2024-05-24T10:08:56.100659Z","shell.execute_reply.started":"2024-05-24T10:08:56.017052Z","shell.execute_reply":"2024-05-24T10:08:56.099777Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# CREATING THE MODEL","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \n    \n    \"\"\"\n    Encoder class for a sequence-to-sequence model with an LSTM architecture.\n\n    Args:\n        input_size (int): Size of the input vocabulary.\n        embedding_size (int): Dimension of the embeddings.\n        hidden_size (int): Number of features in the hidden state of the LSTM.\n        num_layers (int): Number of recurrent layers in the LSTM.\n        p (float): Dropout probability.\n\n    Attributes:\n        dropout (nn.Dropout): Dropout layer.\n        hidden_size (int): Number of features in the hidden state of the LSTM.\n        num_layers (int): Number of recurrent layers in the LSTM.\n        embedding (nn.Embedding): Embedding layer that converts input tokens to embeddings.\n        lstm (nn.LSTM): LSTM layer for encoding the input sequence.\n\n    Methods:\n        forward(x):\n            Forward pass through the encoder.\n            Args:\n                x (torch.Tensor): Input tensor of shape (N, seq_length), where N is the batch size.\n            Returns:\n                tuple: Tuple containing the hidden state and cell state from the LSTM.\n    \"\"\"\n        \n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n        super(Encoder, self).__init__()\n        self.dropout = nn.Dropout(p)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p,batch_first=True)\n\n    def forward(self, x):\n        # x shape: (N,seq_length) where N is batch size\n        embedding = self.dropout(self.embedding(x))\n        # embedding shape: (N,seq_length, embedding_size)\n\n        outputs, (hidden, cell) = self.lstm(embedding)\n        # outputs shape: (N,seq_length, hidden_size)\n\n        return hidden, cell\n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:57.144110Z","iopub.execute_input":"2024-05-24T10:08:57.144822Z","iopub.status.idle":"2024-05-24T10:08:57.153951Z","shell.execute_reply.started":"2024-05-24T10:08:57.144788Z","shell.execute_reply":"2024-05-24T10:08:57.152857Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    \n    \"\"\"\n    Decoder class for a sequence-to-sequence model with an LSTM architecture.\n\n    Args:\n        input_size (int): Size of the input vocabulary.\n        embedding_size (int): Dimension of the embeddings.\n        hidden_size (int): Number of features in the hidden state of the LSTM.\n        output_size (int): Size of the output vocabulary.\n        num_layers (int): Number of recurrent layers in the LSTM.\n        p (float): Dropout probability.\n\n    Attributes:\n        dropout (nn.Dropout): Dropout layer.\n        hidden_size (int): Number of features in the hidden state of the LSTM.\n        num_layers (int): Number of recurrent layers in the LSTM.\n        embedding (nn.Embedding): Embedding layer that converts input tokens to embeddings.\n        lstm (nn.LSTM): LSTM layer for decoding the input sequence.\n        fc (nn.Linear): Fully connected layer for producing output predictions.\n\n    Methods:\n        forward(x, hidden, cell):\n            Forward pass through the decoder.\n            Args:\n                x (torch.Tensor): Input tensor of shape (N), where N is the batch size.\n                hidden (torch.Tensor): Hidden state tensor of shape (num_layers, N, hidden_size).\n                cell (torch.Tensor): Cell state tensor of shape (num_layers, N, hidden_size).\n            Returns:\n                tuple: Tuple containing the predictions, hidden state, and cell state.\n    \"\"\"\n        \n    def __init__(\n        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n    ):\n        super(Decoder, self).__init__()\n        self.dropout = nn.Dropout(p)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p,batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, hidden, cell):\n\n        # x shape: (N) where N is for batch size, we want it to be (N,1), seq_length\n        # is 1 here because we are sending in a single word and not a sentence\n        x = x.unsqueeze(1)\n        #after unsqueeze it becomes [64,1], where 64 is batch size\n\n        embedding = self.dropout(self.embedding(x))\n\n        # embedding shape: (N,1, embedding_size)\n\n        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n        # outputs shape: (N,1, hidden_size)\n\n        predictions = self.fc(outputs)\n\n\n        # predictions shape: (N,1, length_target_vocabulary) to send it to\n        # loss function we want it to be (N, length_target_vocabulary) so we're\n        # just gonna remove the first dim\n        predictions = predictions.squeeze(1)\n        \n    \n        \n        return predictions, hidden, cell\n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:57.440227Z","iopub.execute_input":"2024-05-24T10:08:57.441080Z","iopub.status.idle":"2024-05-24T10:08:57.450573Z","shell.execute_reply.started":"2024-05-24T10:08:57.441051Z","shell.execute_reply":"2024-05-24T10:08:57.449684Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    \"\"\"\n    Sequence-to-Sequence (Seq2Seq) model composed of an encoder and a decoder.\n\n    Args:\n        encoder (nn.Module): Encoder module.\n        decoder (nn.Module): Decoder module.\n\n    Attributes:\n        encoder (nn.Module): Encoder module.\n        decoder (nn.Module): Decoder module.\n\n    Methods:\n        forward(source, target):\n            Forward pass through the Seq2Seq model.\n            Args:\n                source (torch.Tensor): Source input tensor.\n                target (torch.Tensor): Target input tensor.\n            Returns:\n                torch.Tensor: Output tensor from the Seq2Seq model.\n    \"\"\"\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target):\n        batch_size = source.shape[0]\n        target_len = target.shape[1]\n#         print(\"target shape is\",target.shape)\n        target_vocab_size = len(nepali_vocab)\n\n        outputs = torch.zeros(batch_size,target_len, target_vocab_size).to(device)\n\n        hidden, cell = self.encoder(source)\n\n        # First input to the Decoder which will be <SOS> token\n        \n        x = target[:,0]\n        for t in range(1, target_len):\n            # Use previous hidden, cell as context from encoder at start\n            output, hidden, cell = self.decoder(x, hidden, cell)\n                \n#             print(\"output shape is\",output.shape)\n            \n            # Store next output prediction\n            outputs[:,t,:] = output\n\n            #directly sending the ground truth for next input\n            x = target[:,t] \n#         print(\"outputs shape is : \",outputs.shape)\n        return outputs\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:57.744186Z","iopub.execute_input":"2024-05-24T10:08:57.744641Z","iopub.status.idle":"2024-05-24T10:08:57.754223Z","shell.execute_reply.started":"2024-05-24T10:08:57.744602Z","shell.execute_reply":"2024-05-24T10:08:57.753183Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Training hyperparameters\nnum_epochs = 100\nlearning_rate = 0.001\nbatch_size = 64\n\n# Model hyperparameters\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninput_size_encoder = len(english_vocab)\ninput_size_decoder = len(nepali_vocab)\noutput_size = len(nepali_vocab)\nencoder_embedding_size = 300\ndecoder_embedding_size = 300\nhidden_size = 1024  \nnum_layers = 2\nenc_dropout = 0.3\ndec_dropout = 0.3","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:58.052580Z","iopub.execute_input":"2024-05-24T10:08:58.052921Z","iopub.status.idle":"2024-05-24T10:08:58.110467Z","shell.execute_reply.started":"2024-05-24T10:08:58.052895Z","shell.execute_reply":"2024-05-24T10:08:58.109522Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\n\ndecoder_net = Decoder(\n    input_size_decoder,\n    decoder_embedding_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    dec_dropout,\n).to(device)\n\nmodel = Seq2Seq(encoder_net, decoder_net).to(device)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Define the loss function\ncriterion = nn.CrossEntropyLoss(ignore_index=padding_index)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:08:59.103672Z","iopub.execute_input":"2024-05-24T10:08:59.104454Z","iopub.status.idle":"2024-05-24T10:09:02.450005Z","shell.execute_reply.started":"2024-05-24T10:08:59.104423Z","shell.execute_reply":"2024-05-24T10:09:02.449186Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Training loop\nepochs=[]\nlosses=[]\nfor epoch in range(num_epochs):\n    epochs.append(epoch)\n    total_loss = 0\n\n    # Set the model to train mode\n    model.train()\n\n    for batch_idx, (source, target) in enumerate(train_loader):\n        # Move tensors to device\n        source = source.to(device)\n        target = target.to(device)\n\n        # Zero the gradients\n        optimizer.zero_grad()\n\n        \n        # Forward pass\n        output = model(source, target)\n        output = output.permute(0,2,1)\n\n        \n        # Calculate the loss\n        loss = criterion(output, target)\n\n        # Backward pass\n        loss.backward()\n\n        # Update weights\n        optimizer.step()\n        \n        # Save the model checkpoint\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss,\n            }, model_checkpoint)\n\n        total_loss += loss.item()\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader)}')\n    \n    mean_loss=total_loss/len(train_loader)\n    losses.append(mean_loss)\n\n    \n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:09:08.290662Z","iopub.execute_input":"2024-05-24T10:09:08.291654Z","iopub.status.idle":"2024-05-24T12:04:34.498346Z","shell.execute_reply.started":"2024-05-24T10:09:08.291619Z","shell.execute_reply":"2024-05-24T12:04:34.496936Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch [1/100], Loss: 5.845293146191222\nEpoch [2/100], Loss: 5.204265883474639\nEpoch [3/100], Loss: 5.007624857353441\nEpoch [4/100], Loss: 4.820989579865427\nEpoch [5/100], Loss: 4.631487629630349\nEpoch [6/100], Loss: 4.426534609361128\nEpoch [7/100], Loss: 4.199090979316018\nEpoch [8/100], Loss: 3.94959485169613\nEpoch [9/100], Loss: 3.6841718500310723\nEpoch [10/100], Loss: 3.43329094395493\nEpoch [11/100], Loss: 3.202870831345067\nEpoch [12/100], Loss: 2.974908315774166\nEpoch [13/100], Loss: 2.762809897914077\nEpoch [14/100], Loss: 2.5603112668702095\nEpoch [15/100], Loss: 2.389006484638561\nEpoch [16/100], Loss: 2.235539674758911\nEpoch [17/100], Loss: 2.0957292318344116\nEpoch [18/100], Loss: 1.9827808358452537\nEpoch [19/100], Loss: 1.8825059442809133\nEpoch [20/100], Loss: 1.8034112164468477\nEpoch [21/100], Loss: 1.7292262929858584\nEpoch [22/100], Loss: 1.658463351654284\nEpoch [23/100], Loss: 1.6089809049259534\nEpoch [24/100], Loss: 1.5496542995626277\nEpoch [25/100], Loss: 1.505299535664645\nEpoch [26/100], Loss: 1.4617337602557559\nEpoch [27/100], Loss: 1.4250440922650425\nEpoch [28/100], Loss: 1.384971727024425\nEpoch [29/100], Loss: 1.3549091418584187\nEpoch [30/100], Loss: 1.32382646112731\nEpoch [31/100], Loss: 1.2913604830250596\nEpoch [32/100], Loss: 1.2604272690686313\nEpoch [33/100], Loss: 1.2299890518188477\nEpoch [34/100], Loss: 1.2091520771835789\nEpoch [35/100], Loss: 1.1896344206549905\nEpoch [36/100], Loss: 1.1594678127404414\nEpoch [37/100], Loss: 1.1380548404924797\nEpoch [38/100], Loss: 1.1231805736368352\nEpoch [39/100], Loss: 1.1034584262154319\nEpoch [40/100], Loss: 1.0890886458483608\nEpoch [41/100], Loss: 1.0762313784974995\nEpoch [42/100], Loss: 1.0655025857867617\nEpoch [43/100], Loss: 1.0555301922740359\nEpoch [44/100], Loss: 1.049103151668202\nEpoch [45/100], Loss: 1.0420329372088115\nEpoch [46/100], Loss: 1.0375657948580654\nEpoch [47/100], Loss: 1.0316745476289229\nEpoch [48/100], Loss: 1.0269729603420605\nEpoch [49/100], Loss: 1.024730561357556\nEpoch [50/100], Loss: 1.0192602421298171\nEpoch [51/100], Loss: 1.016896164778507\nEpoch [52/100], Loss: 1.0150907292510525\nEpoch [53/100], Loss: 1.0148969527446863\nEpoch [54/100], Loss: 1.011563525055394\nEpoch [55/100], Loss: 1.0100813724777915\nEpoch [56/100], Loss: 1.0093087788784143\nEpoch [57/100], Loss: 1.0087014400597774\nEpoch [58/100], Loss: 1.0052420460816585\nEpoch [59/100], Loss: 1.0045867471983938\nEpoch [60/100], Loss: 1.0057267564715762\nEpoch [61/100], Loss: 1.0040277965141065\nEpoch [62/100], Loss: 1.0042220588886377\nEpoch [63/100], Loss: 1.0016326687552712\nEpoch [64/100], Loss: 1.0006685600136265\nEpoch [65/100], Loss: 0.9982456131414934\nEpoch [66/100], Loss: 1.0002877314885457\nEpoch [67/100], Loss: 1.0012049548553699\nEpoch [68/100], Loss: 1.0006746740052195\nEpoch [69/100], Loss: 1.0010308677499944\nEpoch [70/100], Loss: 0.9981190652558298\nEpoch [71/100], Loss: 0.9984582301342126\nEpoch [72/100], Loss: 0.9998260700341427\nEpoch [73/100], Loss: 0.9975280093424248\nEpoch [74/100], Loss: 0.9999774658318722\nEpoch [75/100], Loss: 0.9989219199527394\nEpoch [76/100], Loss: 0.9979105971076272\nEpoch [77/100], Loss: 1.0010374910903699\nEpoch [78/100], Loss: 0.9984484314918518\nEpoch [79/100], Loss: 0.9996396826975273\nEpoch [80/100], Loss: 0.9991902203270884\nEpoch [81/100], Loss: 0.9959266239946539\nEpoch [82/100], Loss: 1.001060639366959\nEpoch [83/100], Loss: 0.9982000173944415\nEpoch [84/100], Loss: 1.0006035873384187\nEpoch [85/100], Loss: 1.0004394740769358\nEpoch [86/100], Loss: 0.9996139371033871\nEpoch [87/100], Loss: 0.9970785849022142\nEpoch [88/100], Loss: 0.9946333061565052\nEpoch [89/100], Loss: 0.9984047105818084\nEpoch [90/100], Loss: 0.9990853884003379\nEpoch [91/100], Loss: 0.9977782386721987\nEpoch [92/100], Loss: 0.9942157503330347\nEpoch [93/100], Loss: 0.9967742417797898\nEpoch [94/100], Loss: 0.9944729516000459\nEpoch [95/100], Loss: 0.9953477816148237\nEpoch [96/100], Loss: 0.9949761683290655\nEpoch [97/100], Loss: 0.9942923784255981\nEpoch [98/100], Loss: 0.9952278715191465\nEpoch [99/100], Loss: 0.9970796559796189\nEpoch [100/100], Loss: 0.9942378455942328\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(mean_loss)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plotting the training loss curve\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(epochs, losses)\n\u001b[1;32m     52\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLosses\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"],"ename":"NameError","evalue":"name 'plt' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Plotting the training loss curve\nplt.plot(epochs, losses)\nplt.xlabel('Epochs')\nplt.ylabel('Losses')\nplt.title('Training Loss Curve')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-24T12:06:11.929529Z","iopub.execute_input":"2024-05-24T12:06:11.929888Z","iopub.status.idle":"2024-05-24T12:06:12.245007Z","shell.execute_reply.started":"2024-05-24T12:06:11.929853Z","shell.execute_reply":"2024-05-24T12:06:12.243933Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluation function\ndef evaluate(model, test_loader, criterion):\n    model.eval()\n    total_loss = 0\n    total_correct = 0\n    total_samples = 0\n\n    with torch.no_grad():\n        for source, target in test_loader:\n            # Move tensors to device\n            source = source.to(device)\n            target = target.to(device)\n\n            # Forward pass\n            output = model(source, target)\n\n            # Reshape output to match the target shape\n            output = output.reshape(-1, output.shape[-1])\n            target = target.reshape(-1)\n\n            # Calculate the loss\n            loss = criterion(output, target)\n            total_loss += loss.item()\n\n\n    # Calculate average loss and accuracy\n    avg_loss = total_loss / len(test_loader)\n    \n\n    return avg_loss\n\n# Evaluate the model on the test dataset\ntest_loss = evaluate(model, test_loader, criterion)\n\n# Print the test loss and accuracy\nprint(f'Test Loss: {test_loss}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T12:06:15.112269Z","iopub.execute_input":"2024-05-24T12:06:15.112753Z","iopub.status.idle":"2024-05-24T12:06:15.460926Z","shell.execute_reply.started":"2024-05-24T12:06:15.112717Z","shell.execute_reply":"2024-05-24T12:06:15.459802Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Test Loss: 5.9523186683654785\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to decode a sequence of tokens using the vocabulary\ndef decode_sequence(sequence, vocab):\n    # Invert the vocabulary dictionary\n    inv_vocab = {v: k for k, v in vocab.items()}\n    \n    decoded_tokens = []\n    for token in sequence:\n#         print(token)\n        token_id = token.item()\n        if token_id == 2:  # Padding token\n            break\n        elif token_id == 0:  # SOS token\n            continue\n        elif token_id == 1:  # EOS ।token\n            break\n        else:\n            # Fallback for unknown tokens\n            decoded_tokens.append(inv_vocab.get(token_id, f\"<unk:{token_id}>\"))\n    return ' '.join(decoded_tokens)\n\n\n# Choose a random index from the test dataset\nfor i in range(11,16):\n    index = i # You can change this to any index you want to check\n\n    # Get the source and target sequences for the chosen index\n    source_sequence = test_dataset[index][0].unsqueeze(0).to(device)\n    # print(source_sequence)\n    target_sequence = test_dataset[index][1].unsqueeze(0).to(device)\n\n\n    # Forward pass\n    model.eval()\n    with torch.no_grad():\n\n\n        output = model(source_sequence, target_sequence)\n\n\n        output = output.squeeze(1)  \n\n        predicted_indices = output.argmax(2).squeeze(0)  \n\n    #     print(predicted_indices.shape)\n\n        # Decode the predicted sequence\n        predicted_translation = decode_sequence(predicted_indices, nepali_vocab)\n\n        # Get the actual target sequence and decode it\n        actual_translation = decode_sequence(target_sequence.squeeze(), nepali_vocab)\n\n\n    # Invert the vocabulary dictionary\n    eng_inv_vocab = {v: k for k, v in english_vocab.items()}\n\n    # print(eng_inv_vocab)\n    eng_decoded=[]\n    for engtoken in source_sequence.squeeze(0):\n        if engtoken != 2:\n            eng_decoded.append(eng_inv_vocab.get(engtoken.item(), f\"<unk:{engtoken}>\"))\n\n    \n    \n    # Initialize the smoothing function\n    smoothing_function = SmoothingFunction().method1\n    score = sentence_bleu([actual_translation.split()],predicted_translation.split(), smoothing_function=smoothing_function)\n    \n    # Print the actual and predicted translations\n    print(\"-----------------------\")\n    print(f'Actual English Sentence : ', ' '.join(eng_decoded))\n    print(f'Actual Translation: {actual_translation}')\n    print(f'Predicted Translation: {predicted_translation}')\n    print(\"BLEU score is : \",score)\n    print(\"------------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-05-24T12:06:21.332500Z","iopub.execute_input":"2024-05-24T12:06:21.332885Z","iopub.status.idle":"2024-05-24T12:06:21.535436Z","shell.execute_reply.started":"2024-05-24T12:06:21.332853Z","shell.execute_reply":"2024-05-24T12:06:21.534422Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"-----------------------\nActual English Sentence :  My birthday is next Monday .\nActual Translation: मेरो जन्मदिन अर्को सोमबार हो ।\nPredicted Translation: मेरो जन्मदिन अर्को हप्ता हो ।\nBLEU score is :  0.25406637407730737\n------------------------\n-----------------------\nActual English Sentence :  I don't have as much money as I used to have .\nActual Translation: मसँग पहिलाको जति पैसा छैन ।\nPredicted Translation: मसँग ती मलाई प्रश्नहरूको जवाफ ।\nBLEU score is :  0.048549177170732344\n------------------------\n-----------------------\nActual English Sentence :  Say my name .\nActual Translation: मेरो नाम भन ।\nPredicted Translation: तिम्री नाम हो ।\nBLEU score is :  0.09554427922043669\n------------------------\n-----------------------\nActual English Sentence :  Tom knows he shouldn't be here .\nActual Translation: टमलाई थाहा छ ऊ यहाँ हुनुहुँदैन ।\nPredicted Translation: टमले पिज्जा थियो जीवन छोटो छ ।\nBLEU score is :  0.039281465090051315\n------------------------\n-----------------------\nActual English Sentence :  Take him to the hospital .\nActual Translation: उहाँलाई अस्पताल लैजानुहोस् ।\nPredicted Translation: उसलाई कुनै लैजानुहोस् ।\nBLEU score is :  0.16990442448471224\n------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
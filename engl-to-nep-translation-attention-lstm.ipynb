{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8503435,"sourceType":"datasetVersion","datasetId":5075111},{"sourceType":"datasetVersion","sourceId":9004306,"datasetId":5424505}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing necessary modules\nimport pandas as pd\nimport numpy as np\nimport torch.nn as nn\nimport torch\nimport matplotlib.pyplot as plt\nimport nltk\nfrom collections import Counter\nfrom torch import optim\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset, DataLoader\nimport random\nfrom nltk.translate.bleu_score import sentence_bleu, corpus_bleu,SmoothingFunction\nimport re\nimport torch.nn.functional as F\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:57:08.807318Z","iopub.execute_input":"2024-07-21T16:57:08.807679Z","iopub.status.idle":"2024-07-21T16:57:08.814178Z","shell.execute_reply.started":"2024-07-21T16:57:08.807650Z","shell.execute_reply":"2024-07-21T16:57:08.813062Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model_checkpoint=\"attention_language_translation.pth\"","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:31:21.660180Z","iopub.execute_input":"2024-07-21T16:31:21.660968Z","iopub.status.idle":"2024-07-21T16:31:21.666438Z","shell.execute_reply.started":"2024-07-21T16:31:21.660931Z","shell.execute_reply":"2024-07-21T16:31:21.665481Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/nepali-english/npi.txt',delimiter='\\t', names=['English','Nepali','Att'])\ndf.drop(columns=['Att'],inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:31:41.663156Z","iopub.execute_input":"2024-07-21T16:31:41.663806Z","iopub.status.idle":"2024-07-21T16:31:41.713416Z","shell.execute_reply.started":"2024-07-21T16:31:41.663772Z","shell.execute_reply":"2024-07-21T16:31:41.712514Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  English        Nepali\n0    Who?           को?\n1   Hide.  लुकाउनुहोस्।\n2   Hide.          लुक।\n3   Stay.    बस्नुहोस्।\n4  Hello!       नमस्ते!","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Nepali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Who?</td>\n      <td>को?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hide.</td>\n      <td>लुकाउनुहोस्।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hide.</td>\n      <td>लुक।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stay.</td>\n      <td>बस्नुहोस्।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hello!</td>\n      <td>नमस्ते!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Function to add spaces around punctuation\ndef tokenize_sentence(sentence):\n    # Regular expression to add space around punctuation\n    sentence = re.sub(r'([,.!?।])', r' \\1 ', sentence)\n    # Removing extra spaces\n    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n    return sentence\n\ndf['English']=df['English'].apply(tokenize_sentence)\ndf[\"Nepali\"]=df['Nepali'].apply(tokenize_sentence)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:31:46.162050Z","iopub.execute_input":"2024-07-21T16:31:46.162632Z","iopub.status.idle":"2024-07-21T16:31:46.230356Z","shell.execute_reply.started":"2024-07-21T16:31:46.162599Z","shell.execute_reply":"2024-07-21T16:31:46.229467Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:31:47.610228Z","iopub.execute_input":"2024-07-21T16:31:47.610921Z","iopub.status.idle":"2024-07-21T16:31:47.616502Z","shell.execute_reply.started":"2024-07-21T16:31:47.610887Z","shell.execute_reply":"2024-07-21T16:31:47.615561Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(2689, 2)"},"metadata":{}}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:31:49.471508Z","iopub.execute_input":"2024-07-21T16:31:49.472354Z","iopub.status.idle":"2024-07-21T16:31:49.482580Z","shell.execute_reply.started":"2024-07-21T16:31:49.472313Z","shell.execute_reply":"2024-07-21T16:31:49.481561Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   English         Nepali\n0    Who ?           को ?\n1   Hide .  लुकाउनुहोस् ।\n2   Hide .          लुक ।\n3   Stay .    बस्नुहोस् ।\n4  Hello !       नमस्ते !","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Nepali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Who ?</td>\n      <td>को ?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hide .</td>\n      <td>लुकाउनुहोस् ।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hide .</td>\n      <td>लुक ।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stay .</td>\n      <td>बस्नुहोस् ।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hello !</td>\n      <td>नमस्ते !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Creating vocabulary for english","metadata":{}},{"cell_type":"code","source":"#getting all tokens for english\n\n#Add SOS and EOS tokens to the Nepali vocabulary\nenglish_vocab = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2} \n\ntokens_english = [token for x in df['English'] for token in x.split()]\n\n#make the token_counter in order to count the number of times the token appearred in the enitre document\ntoken_counter_english = Counter(tokens_english)\n\n# Create the vocabulary dictionary\nenglish_vocab.update({token: idx + 3 for idx, token in enumerate(token_counter_english)})","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:32:03.854159Z","iopub.execute_input":"2024-07-21T16:32:03.854524Z","iopub.status.idle":"2024-07-21T16:32:03.865379Z","shell.execute_reply.started":"2024-07-21T16:32:03.854496Z","shell.execute_reply":"2024-07-21T16:32:03.864438Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"len(english_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:32:06.482374Z","iopub.execute_input":"2024-07-21T16:32:06.482745Z","iopub.status.idle":"2024-07-21T16:32:06.488377Z","shell.execute_reply.started":"2024-07-21T16:32:06.482694Z","shell.execute_reply":"2024-07-21T16:32:06.487477Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"2178"},"metadata":{}}]},{"cell_type":"markdown","source":"Creating vocabulary for Nepali","metadata":{}},{"cell_type":"code","source":"df['Nepali']='<SOS>' + \" \" + df['Nepali'] + \" \" +  '<EOS>'","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:32:08.777756Z","iopub.execute_input":"2024-07-21T16:32:08.778398Z","iopub.status.idle":"2024-07-21T16:32:08.784558Z","shell.execute_reply.started":"2024-07-21T16:32:08.778367Z","shell.execute_reply":"2024-07-21T16:32:08.783647Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Add SOS and EOS tokens to the Nepali vocabulary\nnepali_vocab = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2} \n\n# Getting all tokens for Nepali and excluding SOS and EOS tokens\ntokens_nepali = [token for x in df['Nepali'] for token in x.split() if token not in ['<SOS>', '<EOS>']]\n\n# Make the token_counter to count the number of times the token appeared in the entire document\ntoken_counter_nepali = Counter(tokens_nepali)\n\n# Update the vocabulary dictionary with other tokens\n# Update the vocabulary dictionary with other tokens\nnepali_vocab.update({token: idx + 3 for idx, token in enumerate(token_counter_nepali)})\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:32:14.522886Z","iopub.execute_input":"2024-07-21T16:32:14.523535Z","iopub.status.idle":"2024-07-21T16:32:14.538973Z","shell.execute_reply.started":"2024-07-21T16:32:14.523502Z","shell.execute_reply":"2024-07-21T16:32:14.537887Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"len(nepali_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:32:32.452593Z","iopub.execute_input":"2024-07-21T16:32:32.453118Z","iopub.status.idle":"2024-07-21T16:32:32.459304Z","shell.execute_reply.started":"2024-07-21T16:32:32.453084Z","shell.execute_reply":"2024-07-21T16:32:32.458356Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"3087"},"metadata":{}}]},{"cell_type":"code","source":"# Convert text to sequences using the vocabulary dictionary\ndf['encoded_english'] = df['English'].apply(lambda x: [english_vocab[token] for token in x.split()])\ndf['encoded_nepali'] = df['Nepali'].apply(lambda x: [nepali_vocab[token] for token in x.split()])\n\n# Convert sequences to tensors and only select the sequence by truncating it to max_length of 20\nmax_length = 20\npadding_index = 2  # Index of <PAD> token\npadded_sequences_english = [seq[:max_length] if len(seq) >= max_length else seq + [padding_index] * (max_length - len(seq)) for seq in df['encoded_english']]\npadded_sequences_nepali = [seq[:max_length] if len(seq) >= max_length else seq + [padding_index] * (max_length - len(seq)) for seq in df['encoded_nepali']]\n\n# Convert the padded sequences to tensors\ndf['padded_sequence_english'] = padded_sequences_english\ndf['padded_sequence_nepali'] = padded_sequences_nepali\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:32:46.982258Z","iopub.execute_input":"2024-07-21T16:32:46.983181Z","iopub.status.idle":"2024-07-21T16:32:47.014578Z","shell.execute_reply.started":"2024-07-21T16:32:46.983132Z","shell.execute_reply":"2024-07-21T16:32:47.013645Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:32:48.643858Z","iopub.execute_input":"2024-07-21T16:32:48.644576Z","iopub.status.idle":"2024-07-21T16:32:48.665178Z","shell.execute_reply.started":"2024-07-21T16:32:48.644540Z","shell.execute_reply":"2024-07-21T16:32:48.664116Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   English                     Nepali encoded_english encoded_nepali  \\\n0    Who ?           <SOS> को ? <EOS>          [3, 4]   [0, 3, 4, 1]   \n1   Hide .  <SOS> लुकाउनुहोस् । <EOS>          [5, 6]   [0, 5, 6, 1]   \n2   Hide .          <SOS> लुक । <EOS>          [5, 6]   [0, 7, 6, 1]   \n3   Stay .    <SOS> बस्नुहोस् । <EOS>          [7, 6]   [0, 8, 6, 1]   \n4  Hello !       <SOS> नमस्ते ! <EOS>          [8, 9]  [0, 9, 10, 1]   \n\n                             padded_sequence_english  \\\n0  [3, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n1  [5, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n2  [5, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n3  [7, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n4  [8, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n\n                              padded_sequence_nepali  \n0  [0, 3, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n1  [0, 5, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n2  [0, 7, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n3  [0, 8, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n4  [0, 9, 10, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Nepali</th>\n      <th>encoded_english</th>\n      <th>encoded_nepali</th>\n      <th>padded_sequence_english</th>\n      <th>padded_sequence_nepali</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Who ?</td>\n      <td>&lt;SOS&gt; को ? &lt;EOS&gt;</td>\n      <td>[3, 4]</td>\n      <td>[0, 3, 4, 1]</td>\n      <td>[3, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 3, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hide .</td>\n      <td>&lt;SOS&gt; लुकाउनुहोस् । &lt;EOS&gt;</td>\n      <td>[5, 6]</td>\n      <td>[0, 5, 6, 1]</td>\n      <td>[5, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 5, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hide .</td>\n      <td>&lt;SOS&gt; लुक । &lt;EOS&gt;</td>\n      <td>[5, 6]</td>\n      <td>[0, 7, 6, 1]</td>\n      <td>[5, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 7, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stay .</td>\n      <td>&lt;SOS&gt; बस्नुहोस् । &lt;EOS&gt;</td>\n      <td>[7, 6]</td>\n      <td>[0, 8, 6, 1]</td>\n      <td>[7, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 8, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hello !</td>\n      <td>&lt;SOS&gt; नमस्ते ! &lt;EOS&gt;</td>\n      <td>[8, 9]</td>\n      <td>[0, 9, 10, 1]</td>\n      <td>[8, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n      <td>[0, 9, 10, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n# Convert 'padded_sequence' to a tensor\npadded_sequences_english = torch.tensor(df['padded_sequence_english'].tolist())\npadded_sequences_nepali = torch.tensor(df['padded_sequence_nepali'].tolist())\n\n# Train-test split\ntrain_sequences_english, test_sequences_english, train_sequences_nepali, test_sequences_nepali = train_test_split(\n    padded_sequences_english, padded_sequences_nepali, test_size=0.2, random_state=42)\n\n# Create TensorDatasets\ntrain_dataset = TensorDataset(train_sequences_english, train_sequences_nepali)\ntest_dataset = TensorDataset(test_sequences_english, test_sequences_nepali)\n\n# Create DataLoaders\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:32:54.413132Z","iopub.execute_input":"2024-07-21T16:32:54.413783Z","iopub.status.idle":"2024-07-21T16:32:54.489662Z","shell.execute_reply.started":"2024-07-21T16:32:54.413750Z","shell.execute_reply":"2024-07-21T16:32:54.488756Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# CREATING THE MODEL","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \n    \n    \"\"\"\n    Encoder class for a sequence-to-sequence model with an LSTM architecture.\n\n    Args:\n        input_size (int): Size of the input vocabulary.\n        embedding_size (int): Dimension of the embeddings.\n        hidden_size (int): Number of features in the hidden state of the LSTM.\n        num_layers (int): Number of recurrent layers in the LSTM.\n        p (float): Dropout probability.\n\n    Attributes:\n        dropout (nn.Dropout): Dropout layer.\n        hidden_size (int): Number of features in the hidden state of the LSTM.\n        num_layers (int): Number of recurrent layers in the LSTM.\n        embedding (nn.Embedding): Embedding layer that converts input tokens to embeddings.\n        lstm (nn.LSTM): LSTM layer for encoding the input sequence.\n\n    Methods:\n        forward(x):\n            Forward pass through the encoder.\n            Args:\n                x (torch.Tensor): Input tensor of shape (N, seq_length), where N is the batch size.\n            Returns:\n                tuple: Tuple containing the hidden state and cell state from the LSTM.\n    \"\"\"\n        \n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n        super(Encoder, self).__init__()\n        self.dropout = nn.Dropout(p)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p,batch_first=True)\n\n    def forward(self, x):\n        # x shape: (N,seq_length) where N is batch size\n        embedding = self.dropout(self.embedding(x))\n        # embedding shape: (N,seq_length, embedding_size)\n\n        outputs, (hidden, cell) = self.lstm(embedding)\n        # outputs shape: (N,seq_length, hidden_size)\n\n        return outputs,hidden, cell\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:33:05.720755Z","iopub.execute_input":"2024-07-21T16:33:05.721116Z","iopub.status.idle":"2024-07-21T16:33:05.730019Z","shell.execute_reply.started":"2024-07-21T16:33:05.721085Z","shell.execute_reply":"2024-07-21T16:33:05.729023Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class BahdanauAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(BahdanauAttention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n\n        weights = F.softmax(scores, dim=-1)\n        context = torch.bmm(weights, keys)\n\n        return context, weights","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:33:15.190215Z","iopub.execute_input":"2024-07-21T16:33:15.190857Z","iopub.status.idle":"2024-07-21T16:33:15.198270Z","shell.execute_reply.started":"2024-07-21T16:33:15.190825Z","shell.execute_reply":"2024-07-21T16:33:15.196964Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    \n    \"\"\"\n    Decoder module for sequence-to-sequence model.\n\n    Args:\n        input_size (int): Size of the input vocabulary.\n        embedding_size (int): Size of the word embeddings.\n        hidden_size (int): Size of the hidden states in the LSTM.\n        output_size (int): Size of the output vocabulary.\n        num_layers (int): Number of layers in the LSTM.\n        p (float): Dropout probability.\n\n    Attributes:\n        dropout (torch.nn.Dropout): Dropout layer.\n        hidden_size (int): Size of the hidden states in the LSTM.\n        num_layers (int): Number of layers in the LSTM.\n        attention (BahdanauAttention): Attention mechanism.\n        embedding (torch.nn.Embedding): Embedding layer.\n        lstm (torch.nn.LSTM): LSTM layer.\n        fc (torch.nn.Linear): Fully connected layer for output.\n    \"\"\"\n    def __init__(\n        self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n    ):\n        super(Decoder, self).__init__()\n        self.dropout = nn.Dropout(p)\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.attention = BahdanauAttention(embedding_size)\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.lstm = nn.LSTM(2 * embedding_size, hidden_size, num_layers, dropout=p,batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, hidden, cell,enc_output):\n#         print(\"x shape for decoder\",x.shape)\n        # x shape: (N) where N is for batch size, we want it to be (N,1), seq_length\n        # is 1 here because we are sending in a single word and not a sentence\n        x = x.unsqueeze(1)\n        #after unsqueeze it becomes [64,1], where 64 is batch size\n\n        embedding = self.dropout(self.embedding(x))\n#         print(\"embedding shape,hello\",embedding.shape,hidden.shape, cell.shape)\n        # embedding shape: (N,1, embedding_size)\n#         print(\"hidden and cell size in decoder\",hidden.size,cell.size)\n        query=hidden[-1,:,:].unsqueeze(0).permute(1,0,2)\n        \n        context,attn_weights=self.attention(query,enc_output)\n        \n        input_lstm=torch.cat((embedding,context),dim=2)\n        \n        outputs, (hidden, cell) = self.lstm(input_lstm, (hidden, cell))\n        # outputs shape: (N,1, hidden_size)\n        \n        predictions = self.fc(outputs)\n#         print(\"predictions shape is \" ,predictions.shape)\n\n        # predictions shape: (N,1, length_target_vocabulary) to send it to\n        # loss function we want it to be (N, length_target_vocabulary) so we're\n        # just gonna remove the first dim\n        predictions = predictions.squeeze(1)\n        \n    \n        \n        return predictions, hidden, cell\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:33:23.230104Z","iopub.execute_input":"2024-07-21T16:33:23.230829Z","iopub.status.idle":"2024-07-21T16:33:23.242125Z","shell.execute_reply.started":"2024-07-21T16:33:23.230794Z","shell.execute_reply":"2024-07-21T16:33:23.241072Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    \n    \n    \"\"\"\n    Sequence-to-Sequence (Seq2Seq) model composed of an encoder and a decoder.\n\n    Args:\n        encoder (nn.Module): Encoder module.\n        decoder (nn.Module): Decoder module.\n\n    Attributes:\n        encoder (nn.Module): Encoder module.\n        decoder (nn.Module): Decoder module.\n\n    Methods:\n        forward(source, target):\n            Forward pass through the Seq2Seq model.\n            Args:\n                source (torch.Tensor): Source input tensor.\n                target (torch.Tensor): Target input tensor.\n            Returns:\n                torch.Tensor: Output tensor from the Seq2Seq model.\n    \"\"\"\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teacher_force_ratio=0.5):\n\n        batch_size = source.shape[0]\n        target_len = target.shape[1]\n\n        target_vocab_size = len(nepali_vocab)\n\n        outputs = torch.zeros(batch_size,target_len, target_vocab_size).to(device)\n\n        enc_output,hidden, cell = self.encoder(source)\n\n        # Grab the first input to the Decoder which will be <SOS> token\n        \n        x = target[:,0]\n\n        for t in range(1, target_len):\n            # Use previous hidden, cell as context from encoder at start\n\n            \n            output, hidden, cell = self.decoder(x, hidden, cell,enc_output)\n\n            \n            # Store next output prediction\n            outputs[:,t,:] = output\n\n\n            #directly sending the ground truth for next input\n            x = target[:,t] \n\n        return outputs\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:33:26.898406Z","iopub.execute_input":"2024-07-21T16:33:26.899112Z","iopub.status.idle":"2024-07-21T16:33:26.907622Z","shell.execute_reply.started":"2024-07-21T16:33:26.899079Z","shell.execute_reply":"2024-07-21T16:33:26.906631Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Training hyperparameters\nnum_epochs = 100\nlearning_rate = 0.001\nbatch_size = 64\n\n# Model hyperparameters\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninput_size_encoder = len(english_vocab)\ninput_size_decoder = len(nepali_vocab)\noutput_size = len(nepali_vocab)\nencoder_embedding_size = 300\ndecoder_embedding_size = 300\nhidden_size = 300 \nnum_layers = 2\nenc_dropout = 0.3\ndec_dropout = 0.3","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:33:31.582760Z","iopub.execute_input":"2024-07-21T16:33:31.583455Z","iopub.status.idle":"2024-07-21T16:33:31.644152Z","shell.execute_reply.started":"2024-07-21T16:33:31.583418Z","shell.execute_reply":"2024-07-21T16:33:31.643172Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\n\ndecoder_net = Decoder(\n    input_size_decoder,\n    decoder_embedding_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    dec_dropout,\n).to(device)\n\nmodel = Seq2Seq(encoder_net, decoder_net).to(device)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Define the loss function\ncriterion = nn.CrossEntropyLoss(ignore_index=padding_index)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:33:44.216956Z","iopub.execute_input":"2024-07-21T16:33:44.217585Z","iopub.status.idle":"2024-07-21T16:33:45.794141Z","shell.execute_reply.started":"2024-07-21T16:33:44.217555Z","shell.execute_reply":"2024-07-21T16:33:45.793375Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nepochs=[]\nlosses=[]\nfor epoch in range(num_epochs):\n    epochs.append(epoch)\n    total_loss = 0\n\n    # Set the model to train mode\n    model.train()\n\n    for batch_idx, (source, target) in enumerate(train_loader):\n        # Move tensors to device\n        source = source.to(device)\n        target = target.to(device)\n\n        # Zero the gradients\n        optimizer.zero_grad()\n\n        \n        # Forward pass\n        output = model(source, target)\n        output = output.permute(0,2,1)\n\n        \n        # Calculate the loss\n        loss = criterion(output, target)\n\n        # Backward pass\n        loss.backward()\n\n        # Update weights\n        optimizer.step()\n        \n        # Save the model checkpoint\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': loss,\n            }, model_checkpoint)\n\n        total_loss += loss.item()\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader)}')\n    \n    mean_loss=total_loss/len(train_loader)\n    losses.append(mean_loss)\n    \n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:33:51.331524Z","iopub.execute_input":"2024-07-21T16:33:51.332399Z","iopub.status.idle":"2024-07-21T16:56:23.384516Z","shell.execute_reply.started":"2024-07-21T16:33:51.332364Z","shell.execute_reply":"2024-07-21T16:56:23.383140Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch [1/100], Loss: 6.235218394886363\nEpoch [2/100], Loss: 5.398127122358843\nEpoch [3/100], Loss: 5.250487905560118\nEpoch [4/100], Loss: 5.135353940905946\nEpoch [5/100], Loss: 5.018959507797703\nEpoch [6/100], Loss: 4.897664720361883\nEpoch [7/100], Loss: 4.776387200211033\nEpoch [8/100], Loss: 4.671327128554836\nEpoch [9/100], Loss: 4.567252029072154\nEpoch [10/100], Loss: 4.463956139304421\nEpoch [11/100], Loss: 4.351000251192035\nEpoch [12/100], Loss: 4.2359740228363965\nEpoch [13/100], Loss: 4.129506277315544\nEpoch [14/100], Loss: 4.028208407488736\nEpoch [15/100], Loss: 3.93636374762564\nEpoch [16/100], Loss: 3.8397983998963325\nEpoch [17/100], Loss: 3.746422478646943\nEpoch [18/100], Loss: 3.645580356771296\nEpoch [19/100], Loss: 3.552450252301765\nEpoch [20/100], Loss: 3.46660819198146\nEpoch [21/100], Loss: 3.380581321138324\nEpoch [22/100], Loss: 3.282433350880941\nEpoch [23/100], Loss: 3.191561641115131\nEpoch [24/100], Loss: 3.1061865922176475\nEpoch [25/100], Loss: 3.0244560169451162\nEpoch [26/100], Loss: 2.9358443563634697\nEpoch [27/100], Loss: 2.8643754106579404\nEpoch [28/100], Loss: 2.7804321520256274\nEpoch [29/100], Loss: 2.700274460243456\nEpoch [30/100], Loss: 2.6281131036353833\nEpoch [31/100], Loss: 2.547354914925315\nEpoch [32/100], Loss: 2.481778354355783\nEpoch [33/100], Loss: 2.4124306548725474\nEpoch [34/100], Loss: 2.3414089824214126\nEpoch [35/100], Loss: 2.2751783529917398\nEpoch [36/100], Loss: 2.2054637200904614\nEpoch [37/100], Loss: 2.1426422451481675\nEpoch [38/100], Loss: 2.081160657333605\nEpoch [39/100], Loss: 2.02152030395739\nEpoch [40/100], Loss: 1.9704460844849094\nEpoch [41/100], Loss: 1.9103209177652996\nEpoch [42/100], Loss: 1.8601857568278457\nEpoch [43/100], Loss: 1.8172852631771204\nEpoch [44/100], Loss: 1.769064682902712\nEpoch [45/100], Loss: 1.720365022168015\nEpoch [46/100], Loss: 1.6774348201173725\nEpoch [47/100], Loss: 1.6389094663388801\nEpoch [48/100], Loss: 1.6017670450788555\nEpoch [49/100], Loss: 1.5615320494680693\nEpoch [50/100], Loss: 1.5280683943719575\nEpoch [51/100], Loss: 1.498064434889591\nEpoch [52/100], Loss: 1.46437791260806\nEpoch [53/100], Loss: 1.4389536886504202\nEpoch [54/100], Loss: 1.406940839507363\nEpoch [55/100], Loss: 1.380180922421542\nEpoch [56/100], Loss: 1.3570829413153909\nEpoch [57/100], Loss: 1.3333299954732258\nEpoch [58/100], Loss: 1.310474572759686\nEpoch [59/100], Loss: 1.2919041929822979\nEpoch [60/100], Loss: 1.2708221890709617\nEpoch [61/100], Loss: 1.2554618878798052\nEpoch [62/100], Loss: 1.2377607750170159\nEpoch [63/100], Loss: 1.2235419136105161\nEpoch [64/100], Loss: 1.2100639523881855\nEpoch [65/100], Loss: 1.19369667226618\nEpoch [66/100], Loss: 1.1815034765185732\nEpoch [67/100], Loss: 1.1711732835480662\nEpoch [68/100], Loss: 1.1580842444390962\nEpoch [69/100], Loss: 1.1472972523082385\nEpoch [70/100], Loss: 1.1387686151446719\nEpoch [71/100], Loss: 1.1289480996854377\nEpoch [72/100], Loss: 1.1204335834040786\nEpoch [73/100], Loss: 1.1141567049604473\nEpoch [74/100], Loss: 1.1074014793742786\nEpoch [75/100], Loss: 1.1002708926345364\nEpoch [76/100], Loss: 1.0944408358949604\nEpoch [77/100], Loss: 1.0854759722044973\nEpoch [78/100], Loss: 1.0836848454041914\nEpoch [79/100], Loss: 1.0806123740745313\nEpoch [80/100], Loss: 1.073491956248428\nEpoch [81/100], Loss: 1.0707916743827588\nEpoch [82/100], Loss: 1.067656291253639\nEpoch [83/100], Loss: 1.0611497994625207\nEpoch [84/100], Loss: 1.0569147648233357\nEpoch [85/100], Loss: 1.051581332177827\nEpoch [86/100], Loss: 1.0523829116965786\nEpoch [87/100], Loss: 1.0475655794143677\nEpoch [88/100], Loss: 1.043994963169098\nEpoch [89/100], Loss: 1.0444588841813984\nEpoch [90/100], Loss: 1.0421339544382962\nEpoch [91/100], Loss: 1.0403375788168474\nEpoch [92/100], Loss: 1.0385390213041594\nEpoch [93/100], Loss: 1.0363935485030666\nEpoch [94/100], Loss: 1.0325077736016475\nEpoch [95/100], Loss: 1.0329211318131648\nEpoch [96/100], Loss: 1.0294764439264934\nEpoch [97/100], Loss: 1.0256173159136917\nEpoch [98/100], Loss: 1.0263068639870845\nEpoch [99/100], Loss: 1.022095759709676\nEpoch [100/100], Loss: 1.0220413840178288\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(mean_loss)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plotting the training loss curve\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(epochs, losses)\n\u001b[1;32m     52\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLosses\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"],"ename":"NameError","evalue":"name 'plt' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Plotting the training loss curve\nplt.plot(epochs, losses)\nplt.xlabel('Epochs')\nplt.ylabel('Losses')\nplt.title('Training Loss Curve')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:57:15.072664Z","iopub.execute_input":"2024-07-21T16:57:15.073074Z","iopub.status.idle":"2024-07-21T16:57:15.349629Z","shell.execute_reply.started":"2024-07-21T16:57:15.073042Z","shell.execute_reply":"2024-07-21T16:57:15.348727Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation function\ndef evaluate(model, test_loader, criterion):\n    model.eval()\n    total_loss = 0\n    total_correct = 0\n    total_samples = 0\n\n    with torch.no_grad():\n        for source, target in test_loader:\n            # Move tensors to device\n            source = source.to(device)\n            target = target.to(device)\n\n            # Forward pass\n            output = model(source, target)\n\n            # Reshape output to match the target shape\n            output = output.reshape(-1, output.shape[-1])\n            target = target.reshape(-1)\n\n            # Calculate the loss\n            loss = criterion(output, target)\n            total_loss += loss.item()\n\n\n    # Calculate average loss and accuracy\n    avg_loss = total_loss / len(test_loader)\n    \n\n    return avg_loss\n\n# Evaluate the model on the test dataset\ntest_loss = evaluate(model, test_loader, criterion)\n\n# Print the test loss and accuracy\nprint(f'Test Loss: {test_loss}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T16:57:32.513961Z","iopub.execute_input":"2024-07-21T16:57:32.514328Z","iopub.status.idle":"2024-07-21T16:57:32.703239Z","shell.execute_reply.started":"2024-07-21T16:57:32.514298Z","shell.execute_reply":"2024-07-21T16:57:32.702248Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Test Loss: 5.381843149662018\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to decode a sequence of tokens using the vocabulary\ndef decode_sequence(sequence, vocab):\n    # Invert the vocabulary dictionary\n    inv_vocab = {v: k for k, v in vocab.items()}\n    \n    decoded_tokens = []\n    for token in sequence:\n\n        token_id = token.item()\n        if token_id == 2:  # Padding token\n            break\n        elif token_id == 0:  # SOS token\n            continue\n        elif token_id == 1:  # EOS ।token\n            break\n        else:\n            # Fallback for unknown tokens\n            decoded_tokens.append(inv_vocab.get(token_id, f\"<unk:{token_id}>\"))\n    return ' '.join(decoded_tokens)\n\n\n# Choose a random index from the test dataset\nfor i in range(1,100):\n    index = i # You can change this to any index you want to check\n\n    # Get the source and target sequences for the chosen index\n    source_sequence = test_dataset[index][0].unsqueeze(0).to(device)\n    # print(source_sequence)\n    target_sequence = test_dataset[index][1].unsqueeze(0).to(device)\n\n\n    # Forward pass\n    model.eval()\n    with torch.no_grad():\n\n\n        output = model(source_sequence, target_sequence)\n\n\n        output = output.squeeze(1)  \n\n        predicted_indices = output.argmax(2).squeeze(0)  \n\n    #     print(predicted_indices.shape)\n\n        # Decode the predicted sequence\n        predicted_translation = decode_sequence(predicted_indices, nepali_vocab)\n\n        # Get the actual target sequence and decode it\n        actual_translation = decode_sequence(target_sequence.squeeze(), nepali_vocab)\n\n\n    # Invert the vocabulary dictionary\n    eng_inv_vocab = {v: k for k, v in english_vocab.items()}\n\n    # print(eng_inv_vocab)\n    eng_decoded=[]\n    for engtoken in source_sequence.squeeze(0):\n        if engtoken != 2:\n            eng_decoded.append(eng_inv_vocab.get(engtoken.item(), f\"<unk:{engtoken}>\"))\n\n    \n    \n    # Initialize the smoothing function\n    smoothing_function = SmoothingFunction().method1\n    score = sentence_bleu([actual_translation.split()],predicted_translation.split(), smoothing_function=smoothing_function)\n    \n    #print the results having bluescore greather than 0.3\n    if score>0.3:\n    \n        # Print the actual and predicted translations\n        print(\"-----------------------\")\n        print(f'Actual English Sentence : ', ' '.join(eng_decoded))\n        print(f'Actual Translation: {actual_translation}')\n        print(f'Predicted Translation: {predicted_translation}')\n        print(\"BLEU score is : \",score)\n        print(\"------------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T17:01:06.557137Z","iopub.execute_input":"2024-07-21T17:01:06.557463Z","iopub.status.idle":"2024-07-21T17:01:08.123334Z","shell.execute_reply.started":"2024-07-21T17:01:06.557439Z","shell.execute_reply":"2024-07-21T17:01:08.122421Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"-----------------------\nActual English Sentence :  I'm very grateful to you .\nActual Translation: म तपाईप्रति धेरै आभारी छु ।\nPredicted Translation: म तपाईप्रति धेरै आभारी छु ।\nBLEU score is :  1.0\n------------------------\n-----------------------\nActual English Sentence :  Take him to the hospital .\nActual Translation: उहाँलाई अस्पताल लैजानुहोस् ।\nPredicted Translation: उसलाई अस्पताल लैजानुहोस् ।\nBLEU score is :  0.3976353643835253\n------------------------\n-----------------------\nActual English Sentence :  I don't want to leave you .\nActual Translation: म तिमीलाई छोड्न चाहन्न ।\nPredicted Translation: म तिमीलाई छोड्न चाहन्न ।\nBLEU score is :  1.0\n------------------------\n-----------------------\nActual English Sentence :  I really liked your story .\nActual Translation: मलाई तपाईको कथा साँच्चै मन पर्यो ।\nPredicted Translation: मलाई तिम्रो कथा साँच्चै मन पर्यो ।\nBLEU score is :  0.6434588841607617\n------------------------\n-----------------------\nActual English Sentence :  You're feeling very sleepy , aren't you ?\nActual Translation: तिमीलाई धेरै निद्रा लागेको छ , हैन ?\nPredicted Translation: तपाईलाई धेरै निद्रा लागेको छ , हैन ?\nBLEU score is :  0.8408964152537145\n------------------------\n-----------------------\nActual English Sentence :  I like the bright colors .\nActual Translation: मलाई उज्यालो रंग मन पर्छ ।\nPredicted Translation: मलाई उज्यालो रंग मन पर्छ ।\nBLEU score is :  1.0\n------------------------\n-----------------------\nActual English Sentence :  He is sick .\nActual Translation: उहाँ बिरामी हुनुहुन्छ ।\nPredicted Translation: ऊ बिरामी हुनुहुन्छ ।\nBLEU score is :  0.3976353643835253\n------------------------\n-----------------------\nActual English Sentence :  He has a large family .\nActual Translation: उसको ठूलो परिवार छ ।\nPredicted Translation: उहाँको ठूलो परिवार छ ।\nBLEU score is :  0.668740304976422\n------------------------\n-----------------------\nActual English Sentence :  I miss you badly .\nActual Translation: मलाई तिम्रो धेरै याद आइरहेको छ ।\nPredicted Translation: मलाई तिम्रो साथ याद आइरहेको छ ।\nBLEU score is :  0.488923022434901\n------------------------\n-----------------------\nActual English Sentence :  Where is the toilet ?\nActual Translation: शौचालय कहाँ छ ?\nPredicted Translation: कसले कहाँ छ ?\nBLEU score is :  0.3976353643835253\n------------------------\n-----------------------\nActual English Sentence :  I can't leave work until five o'clock .\nActual Translation: म ५ बजेसम्म काम छोड्न सक्दिन ।\nPredicted Translation: म ५ बजेसम्म काम छोड्न सक्दिन ।\nBLEU score is :  1.0\n------------------------\n-----------------------\nActual English Sentence :  Thanks for the cookies .\nActual Translation: कुकीज को लागी धन्यवाद ।\nPredicted Translation: कुकीज को लागी धन्यवाद ।\nBLEU score is :  1.0\n------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}